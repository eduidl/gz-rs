// This file is generated by rust-protobuf 3.7.2. Do not edit
// .proto file is parsed by protoc 3.21.12
// @generated

// https://github.com/rust-lang/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy::all)]

#![allow(unused_attributes)]
#![cfg_attr(rustfmt, rustfmt::skip)]

#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unused_results)]
#![allow(unused_mut)]

//! Generated file from `ignition/msgs/camerasensor.proto`

/// Generated files are compatible only with the same version
/// of protobuf runtime.
const _PROTOBUF_VERSION_CHECK: () = ::protobuf::VERSION_3_7_2;

#[derive(::gz_msgs_common::IgnMessage)]
// @@protoc_insertion_point(message:ignition.msgs.CameraSensor)
#[derive(PartialEq,Clone,Default,Debug)]
pub struct CameraSensor {
    // message fields
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.header)
    pub header: ::protobuf::MessageField<super::header::Header>,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.horizontal_fov)
    pub horizontal_fov: f64,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.image_size)
    pub image_size: ::protobuf::MessageField<super::vector2d::Vector2d>,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.image_format)
    pub image_format: ::std::string::String,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.near_clip)
    pub near_clip: f64,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.far_clip)
    pub far_clip: f64,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.save_enabled)
    pub save_enabled: bool,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.save_path)
    pub save_path: ::std::string::String,
    // @@protoc_insertion_point(field:ignition.msgs.CameraSensor.distortion)
    pub distortion: ::protobuf::MessageField<super::distortion::Distortion>,
    // special fields
    // @@protoc_insertion_point(special_field:ignition.msgs.CameraSensor.special_fields)
    pub special_fields: ::protobuf::SpecialFields,
}

impl<'a> ::std::default::Default for &'a CameraSensor {
    fn default() -> &'a CameraSensor {
        <CameraSensor as ::protobuf::Message>::default_instance()
    }
}

impl CameraSensor {
    pub fn new() -> CameraSensor {
        ::std::default::Default::default()
    }

    fn generated_message_descriptor_data() -> ::protobuf::reflect::GeneratedMessageDescriptorData {
        let mut fields = ::std::vec::Vec::with_capacity(9);
        let mut oneofs = ::std::vec::Vec::with_capacity(0);
        fields.push(::protobuf::reflect::rt::v2::make_message_field_accessor::<_, super::header::Header>(
            "header",
            |m: &CameraSensor| { &m.header },
            |m: &mut CameraSensor| { &mut m.header },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "horizontal_fov",
            |m: &CameraSensor| { &m.horizontal_fov },
            |m: &mut CameraSensor| { &mut m.horizontal_fov },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_message_field_accessor::<_, super::vector2d::Vector2d>(
            "image_size",
            |m: &CameraSensor| { &m.image_size },
            |m: &mut CameraSensor| { &mut m.image_size },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "image_format",
            |m: &CameraSensor| { &m.image_format },
            |m: &mut CameraSensor| { &mut m.image_format },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "near_clip",
            |m: &CameraSensor| { &m.near_clip },
            |m: &mut CameraSensor| { &mut m.near_clip },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "far_clip",
            |m: &CameraSensor| { &m.far_clip },
            |m: &mut CameraSensor| { &mut m.far_clip },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "save_enabled",
            |m: &CameraSensor| { &m.save_enabled },
            |m: &mut CameraSensor| { &mut m.save_enabled },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_simpler_field_accessor::<_, _>(
            "save_path",
            |m: &CameraSensor| { &m.save_path },
            |m: &mut CameraSensor| { &mut m.save_path },
        ));
        fields.push(::protobuf::reflect::rt::v2::make_message_field_accessor::<_, super::distortion::Distortion>(
            "distortion",
            |m: &CameraSensor| { &m.distortion },
            |m: &mut CameraSensor| { &mut m.distortion },
        ));
        ::protobuf::reflect::GeneratedMessageDescriptorData::new_2::<CameraSensor>(
            "CameraSensor",
            fields,
            oneofs,
        )
    }
}

impl ::protobuf::Message for CameraSensor {
    const NAME: &'static str = "CameraSensor";

    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::Result<()> {
        while let Some(tag) = is.read_raw_tag_or_eof()? {
            match tag {
                10 => {
                    ::protobuf::rt::read_singular_message_into_field(is, &mut self.header)?;
                },
                17 => {
                    self.horizontal_fov = is.read_double()?;
                },
                26 => {
                    ::protobuf::rt::read_singular_message_into_field(is, &mut self.image_size)?;
                },
                34 => {
                    self.image_format = is.read_string()?;
                },
                41 => {
                    self.near_clip = is.read_double()?;
                },
                49 => {
                    self.far_clip = is.read_double()?;
                },
                56 => {
                    self.save_enabled = is.read_bool()?;
                },
                66 => {
                    self.save_path = is.read_string()?;
                },
                74 => {
                    ::protobuf::rt::read_singular_message_into_field(is, &mut self.distortion)?;
                },
                tag => {
                    ::protobuf::rt::read_unknown_or_skip_group(tag, is, self.special_fields.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u64 {
        let mut my_size = 0;
        if let Some(v) = self.header.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint64_size(len) + len;
        }
        if self.horizontal_fov != 0. {
            my_size += 1 + 8;
        }
        if let Some(v) = self.image_size.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint64_size(len) + len;
        }
        if !self.image_format.is_empty() {
            my_size += ::protobuf::rt::string_size(4, &self.image_format);
        }
        if self.near_clip != 0. {
            my_size += 1 + 8;
        }
        if self.far_clip != 0. {
            my_size += 1 + 8;
        }
        if self.save_enabled != false {
            my_size += 1 + 1;
        }
        if !self.save_path.is_empty() {
            my_size += ::protobuf::rt::string_size(8, &self.save_path);
        }
        if let Some(v) = self.distortion.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint64_size(len) + len;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.special_fields.unknown_fields());
        self.special_fields.cached_size().set(my_size as u32);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::Result<()> {
        if let Some(v) = self.header.as_ref() {
            ::protobuf::rt::write_message_field_with_cached_size(1, v, os)?;
        }
        if self.horizontal_fov != 0. {
            os.write_double(2, self.horizontal_fov)?;
        }
        if let Some(v) = self.image_size.as_ref() {
            ::protobuf::rt::write_message_field_with_cached_size(3, v, os)?;
        }
        if !self.image_format.is_empty() {
            os.write_string(4, &self.image_format)?;
        }
        if self.near_clip != 0. {
            os.write_double(5, self.near_clip)?;
        }
        if self.far_clip != 0. {
            os.write_double(6, self.far_clip)?;
        }
        if self.save_enabled != false {
            os.write_bool(7, self.save_enabled)?;
        }
        if !self.save_path.is_empty() {
            os.write_string(8, &self.save_path)?;
        }
        if let Some(v) = self.distortion.as_ref() {
            ::protobuf::rt::write_message_field_with_cached_size(9, v, os)?;
        }
        os.write_unknown_fields(self.special_fields.unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn special_fields(&self) -> &::protobuf::SpecialFields {
        &self.special_fields
    }

    fn mut_special_fields(&mut self) -> &mut ::protobuf::SpecialFields {
        &mut self.special_fields
    }

    fn new() -> CameraSensor {
        CameraSensor::new()
    }

    fn clear(&mut self) {
        self.header.clear();
        self.horizontal_fov = 0.;
        self.image_size.clear();
        self.image_format.clear();
        self.near_clip = 0.;
        self.far_clip = 0.;
        self.save_enabled = false;
        self.save_path.clear();
        self.distortion.clear();
        self.special_fields.clear();
    }

    fn default_instance() -> &'static CameraSensor {
        static instance: CameraSensor = CameraSensor {
            header: ::protobuf::MessageField::none(),
            horizontal_fov: 0.,
            image_size: ::protobuf::MessageField::none(),
            image_format: ::std::string::String::new(),
            near_clip: 0.,
            far_clip: 0.,
            save_enabled: false,
            save_path: ::std::string::String::new(),
            distortion: ::protobuf::MessageField::none(),
            special_fields: ::protobuf::SpecialFields::new(),
        };
        &instance
    }
}

impl ::protobuf::MessageFull for CameraSensor {
    fn descriptor() -> ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::Lazy::new();
        descriptor.get(|| file_descriptor().message_by_package_relative_name("CameraSensor").unwrap()).clone()
    }
}

impl ::std::fmt::Display for CameraSensor {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for CameraSensor {
    type RuntimeType = ::protobuf::reflect::rt::RuntimeTypeMessage<Self>;
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n\x20ignition/msgs/camerasensor.proto\x12\rignition.msgs\x1a\x1cignitio\
    n/msgs/vector2d.proto\x1a\x1eignition/msgs/distortion.proto\x1a\x1aignit\
    ion/msgs/header.proto\"\xf2\x02\n\x0cCameraSensor\x12-\n\x06header\x18\
    \x01\x20\x01(\x0b2\x15.ignition.msgs.HeaderR\x06header\x12%\n\x0ehorizon\
    tal_fov\x18\x02\x20\x01(\x01R\rhorizontalFov\x126\n\nimage_size\x18\x03\
    \x20\x01(\x0b2\x17.ignition.msgs.Vector2dR\timageSize\x12!\n\x0cimage_fo\
    rmat\x18\x04\x20\x01(\tR\x0bimageFormat\x12\x1b\n\tnear_clip\x18\x05\x20\
    \x01(\x01R\x08nearClip\x12\x19\n\x08far_clip\x18\x06\x20\x01(\x01R\x07fa\
    rClip\x12!\n\x0csave_enabled\x18\x07\x20\x01(\x08R\x0bsaveEnabled\x12\
    \x1b\n\tsave_path\x18\x08\x20\x01(\tR\x08savePath\x129\n\ndistortion\x18\
    \t\x20\x01(\x0b2\x19.ignition.msgs.DistortionR\ndistortionB'\n\x11com.ig\
    nition.msgsB\x12CameraSensorProtosb\x06proto3\
";

/// `FileDescriptorProto` object which was a source for this generated file
fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    static file_descriptor_proto_lazy: ::protobuf::rt::Lazy<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::rt::Lazy::new();
    file_descriptor_proto_lazy.get(|| {
        ::protobuf::Message::parse_from_bytes(file_descriptor_proto_data).unwrap()
    })
}

/// `FileDescriptor` object which allows dynamic access to files
pub fn file_descriptor() -> &'static ::protobuf::reflect::FileDescriptor {
    static generated_file_descriptor_lazy: ::protobuf::rt::Lazy<::protobuf::reflect::GeneratedFileDescriptor> = ::protobuf::rt::Lazy::new();
    static file_descriptor: ::protobuf::rt::Lazy<::protobuf::reflect::FileDescriptor> = ::protobuf::rt::Lazy::new();
    file_descriptor.get(|| {
        let generated_file_descriptor = generated_file_descriptor_lazy.get(|| {
            let mut deps = ::std::vec::Vec::with_capacity(3);
            deps.push(super::vector2d::file_descriptor().clone());
            deps.push(super::distortion::file_descriptor().clone());
            deps.push(super::header::file_descriptor().clone());
            let mut messages = ::std::vec::Vec::with_capacity(1);
            messages.push(CameraSensor::generated_message_descriptor_data());
            let mut enums = ::std::vec::Vec::with_capacity(0);
            ::protobuf::reflect::GeneratedFileDescriptor::new_generated(
                file_descriptor_proto(),
                deps,
                messages,
                enums,
            )
        });
        ::protobuf::reflect::FileDescriptor::new_generated_2(generated_file_descriptor)
    })
}
